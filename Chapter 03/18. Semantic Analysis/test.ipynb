{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import datasets\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab, FastText\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import AmazonReviewFull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "Package `torchdata` not found. Please install following instructions at `https://github.com/pytorch/data`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\andre\\Documents\\Strive_repository\\local_exercise\\Chapter 03\\18. Semantic Analysis\\test.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/Documents/Strive_repository/local_exercise/Chapter%2003/18.%20Semantic%20Analysis/test.ipynb#ch0000001?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchtext\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m AmazonReviewFull\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/andre/Documents/Strive_repository/local_exercise/Chapter%2003/18.%20Semantic%20Analysis/test.ipynb#ch0000001?line=1'>2</a>\u001b[0m train, test \u001b[39m=\u001b[39m AmazonReviewFull()\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\DL\\lib\\site-packages\\torchtext\\data\\datasets_utils.py:248\u001b[0m, in \u001b[0;36m_create_dataset_directory.<locals>.decorator.<locals>.wrapper\u001b[1;34m(root, *args, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(new_root):\n\u001b[0;32m    247\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(new_root)\n\u001b[1;32m--> 248\u001b[0m \u001b[39mreturn\u001b[39;00m fn(root\u001b[39m=\u001b[39mnew_root, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\DL\\lib\\site-packages\\torchtext\\data\\datasets_utils.py:212\u001b[0m, in \u001b[0;36m_wrap_split_argument_with_fn.<locals>.new_fn\u001b[1;34m(root, split, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m result \u001b[39m=\u001b[39m []\n\u001b[0;32m    211\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m _check_default_set(split, splits, fn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m):\n\u001b[1;32m--> 212\u001b[0m     result\u001b[39m.\u001b[39mappend(fn(root, item, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n\u001b[0;32m    213\u001b[0m \u001b[39mreturn\u001b[39;00m _wrap_datasets(\u001b[39mtuple\u001b[39m(result), split)\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\DL\\lib\\site-packages\\torchtext\\datasets\\amazonreviewfull.py:57\u001b[0m, in \u001b[0;36mAmazonReviewFull\u001b[1;34m(root, split)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39m\"\"\"AmazonReviewFull Dataset\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \n\u001b[0;32m     43\u001b[0m \u001b[39mFor additional details refer to https://arxiv.org/abs/1509.01626\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39m:rtype: (int, str)\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_module_available(\u001b[39m\"\u001b[39m\u001b[39mtorchdata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m(\n\u001b[0;32m     58\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPackage `torchdata` not found. Please install following instructions at `https://github.com/pytorch/data`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     59\u001b[0m     )\n\u001b[0;32m     61\u001b[0m url_dp \u001b[39m=\u001b[39m IterableWrapper([URL])\n\u001b[0;32m     62\u001b[0m cache_compressed_dp \u001b[39m=\u001b[39m url_dp\u001b[39m.\u001b[39mon_disk_cache(\n\u001b[0;32m     63\u001b[0m     filepath_fn\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root, _PATH),\n\u001b[0;32m     64\u001b[0m     hash_dict\u001b[39m=\u001b[39m{os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root, _PATH): MD5},\n\u001b[0;32m     65\u001b[0m     hash_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmd5\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     66\u001b[0m )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: Package `torchdata` not found. Please install following instructions at `https://github.com/pytorch/data`"
     ]
    }
   ],
   "source": [
    "from torchtext.datasets import AmazonReviewFull\n",
    "train, test = AmazonReviewFull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>mens ultrasheer</td>\n",
       "      <td>This model may be ok for sedentary types, but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Surprisingly delightful</td>\n",
       "      <td>This is a fast read filled with unexpected hum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Works, but not as advertised</td>\n",
       "      <td>I bought one of these chargers..the instructio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Oh dear</td>\n",
       "      <td>I was excited to find a book ostensibly about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Incorrect disc!</td>\n",
       "      <td>I am a big JVC fan, but I do not like this mod...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                             1  \\\n",
       "0  1               mens ultrasheer   \n",
       "1  4       Surprisingly delightful   \n",
       "2  2  Works, but not as advertised   \n",
       "3  2                       Oh dear   \n",
       "4  2               Incorrect disc!   \n",
       "\n",
       "                                                   2  \n",
       "0  This model may be ok for sedentary types, but ...  \n",
       "1  This is a fast read filled with unexpected hum...  \n",
       "2  I bought one of these chargers..the instructio...  \n",
       "3  I was excited to find a book ostensibly about ...  \n",
       "4  I am a big JVC fan, but I do not like this mod...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading train data\n",
    "\n",
    "# train_df = pd.read_csv(\".data/Amazon/3000test.csv\", nrows=3000, header=0, index_col=0)\n",
    "# train_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rename columns\n",
    "# train_df.rename({'0':\"star\", '1':\"rating1\", '2':\"rating2\"}, axis=1, inplace=True)\n",
    "\n",
    "# # merge the two reviews columns\n",
    "# train_df[\"review\"] = train_df[\"review\"] = train_df[\"rating1\"] + \" \" +  train_df[\"rating2\"]\n",
    "\n",
    "# # drop unnecessary columns\n",
    "# train_df.drop(columns=[\"rating1\", \"rating2\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>mens ultrasheer This model may be ok for seden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Surprisingly delightful This is a fast read fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Works, but not as advertised I bought one of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Oh dear I was excited to find a book ostensibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Incorrect disc! I am a big JVC fan, but I do n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star                                             review\n",
       "0     1  mens ultrasheer This model may be ok for seden...\n",
       "1     4  Surprisingly delightful This is a fast read fi...\n",
       "2     2  Works, but not as advertised I bought one of t...\n",
       "3     2  Oh dear I was excited to find a book ostensibl...\n",
       "4     2  Incorrect disc! I am a big JVC fan, but I do n..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>mens ultrasheer</td>\n",
       "      <td>This model may be ok for sedentary types, but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Surprisingly delightful</td>\n",
       "      <td>This is a fast read filled with unexpected hum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Works, but not as advertised</td>\n",
       "      <td>I bought one of these chargers..the instructio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Oh dear</td>\n",
       "      <td>I was excited to find a book ostensibly about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Incorrect disc!</td>\n",
       "      <td>I am a big JVC fan, but I do not like this mod...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                             1  \\\n",
       "0  1               mens ultrasheer   \n",
       "1  4       Surprisingly delightful   \n",
       "2  2  Works, but not as advertised   \n",
       "3  2                       Oh dear   \n",
       "4  2               Incorrect disc!   \n",
       "\n",
       "                                                   2  \n",
       "0  This model may be ok for sedentary types, but ...  \n",
       "1  This is a fast read filled with unexpected hum...  \n",
       "2  I bought one of these chargers..the instructio...  \n",
       "3  I was excited to find a book ostensibly about ...  \n",
       "4  I am a big JVC fan, but I do not like this mod...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_df = pd.read_csv(\".data/Amazon/3000test.csv\", nrows=3000, header=0, index_col=0)\n",
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rename columns\n",
    "# test_df.rename({'0':\"star\", '1':\"rating1\", '2':\"rating2\"}, axis=1, inplace=True)\n",
    "\n",
    "# # merge the two reviews columns\n",
    "# test_df[\"review\"] = test_df[\"review\"] = test_df[\"rating1\"] + \" \" +  test_df[\"rating2\"]\n",
    "\n",
    "# # drop unnecessary columns\n",
    "# test_df.drop(columns=[\"rating1\", \"rating2\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>mens ultrasheer This model may be ok for seden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Surprisingly delightful This is a fast read fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Works, but not as advertised I bought one of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Oh dear I was excited to find a book ostensibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Incorrect disc! I am a big JVC fan, but I do n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star                                             review\n",
       "0     1  mens ultrasheer This model may be ok for seden...\n",
       "1     4  Surprisingly delightful This is a fast read fi...\n",
       "2     2  Works, but not as advertised I bought one of t...\n",
       "3     2  Oh dear I was excited to find a book ostensibl...\n",
       "4     2  Incorrect disc! I am a big JVC fan, but I do n..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a sample of training data\n",
    "\n",
    "# train_df = train_df.groupby('star', group_keys=False).apply(lambda x: x.sample(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>1</td>\n",
       "      <td>great american spice company stay away from Gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1</td>\n",
       "      <td>Actually, this book is not worth one star. Thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>1</td>\n",
       "      <td>Please dont buy if you are entirely new to Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>1</td>\n",
       "      <td>Defective Product The product was delivered on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>1</td>\n",
       "      <td>blleeuurrgghhhh i have listened to this single...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>5</td>\n",
       "      <td>WHY IS THIS NOT AVAILABLE IN WIDESCREEN???? Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>5</td>\n",
       "      <td>This is a fantastic show. There's really nothi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>5</td>\n",
       "      <td>Use as a chair I'm glad I bought the largest o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>5</td>\n",
       "      <td>Great gift and a very useful item I purchased ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>5</td>\n",
       "      <td>More real than history These 100 years in Maco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      star                                             review\n",
       "1632     1  great american spice company stay away from Gr...\n",
       "142      1  Actually, this book is not worth one star. Thi...\n",
       "1779     1  Please dont buy if you are entirely new to Jav...\n",
       "1917     1  Defective Product The product was delivered on...\n",
       "1643     1  blleeuurrgghhhh i have listened to this single...\n",
       "...    ...                                                ...\n",
       "1930     5  WHY IS THIS NOT AVAILABLE IN WIDESCREEN???? Th...\n",
       "1238     5  This is a fantastic show. There's really nothi...\n",
       "2960     5  Use as a chair I'm glad I bought the largest o...\n",
       "1884     5  Great gift and a very useful item I purchased ...\n",
       "1546     5  More real than history These 100 years in Maco...\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample test_df\n",
    "\n",
    "# test_df = test_df.groupby('star', group_keys=False).apply(lambda x: x.sample(200))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2359</th>\n",
       "      <td>1</td>\n",
       "      <td>OMG this is so awful how can you people listen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>1</td>\n",
       "      <td>Another person who can't believe they changed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>1</td>\n",
       "      <td>Stained after two uses I bought these. After t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>1</td>\n",
       "      <td>Ripoff ! Don't Buy From CMMA Accessories ! I r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>1</td>\n",
       "      <td>Piece of CR--AP - try calling their support ! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>5</td>\n",
       "      <td>A Scholarly Book for Serious Students of Yiddi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product for the price Have been buying d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2436</th>\n",
       "      <td>5</td>\n",
       "      <td>Rare Glow Fribee Delivered Fast I live in a sm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>5</td>\n",
       "      <td>Of Mice and Men George and Lennie are best fri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>5</td>\n",
       "      <td>like the critics say: RIVETING! the book was g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      star                                             review\n",
       "2359     1  OMG this is so awful how can you people listen...\n",
       "596      1  Another person who can't believe they changed ...\n",
       "846      1  Stained after two uses I bought these. After t...\n",
       "956      1  Ripoff ! Don't Buy From CMMA Accessories ! I r...\n",
       "287      1  Piece of CR--AP - try calling their support ! ...\n",
       "...    ...                                                ...\n",
       "1522     5  A Scholarly Book for Serious Students of Yiddi...\n",
       "1948     5  Great product for the price Have been buying d...\n",
       "2436     5  Rare Glow Fribee Delivered Fast I live in a sm...\n",
       "2514     5  Of Mice and Men George and Lennie are best fri...\n",
       "439      5  like the critics say: RIVETING! the book was g...\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocessing(sentence):\n",
    "#     \"\"\"\n",
    "#     params sentence: a str containing the sentence we want to preprocess\n",
    "#     return the tokens list\n",
    "#     \"\"\"\n",
    "#     doc = nlp(sentence)\n",
    "#     tokens = [token.lemma_ for token in doc if not token.is_punct and not token.is_stop]\n",
    "#     return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TrainData(Dataset):\n",
    "#     # initiate the class with df and maximum number of tokens as argument\n",
    "#     def __init__(self, df, max_seq_len=32):\n",
    "#         self.max_seq_len = max_seq_len\n",
    "#         counter = Counter()    # instanziate counter\n",
    "#         train_iter = iter(df.review.values)    # make the review column iterable\n",
    "#         for text in train_iter:\n",
    "#             counter.update(preprocessing(text))    # update the counter object with the number of words and occurrencies\n",
    "#         self.vocab = Vocab(counter, min_freq=1)    # create pytorch Vocab from the counter with all the words (min_freq=1)\n",
    "#         self.vocab.load_vectors(\"fasttext.simple.300d\")    # load pretrained embeddings\n",
    "#         label_pipeline = lambda x: int(x) -1     # make the label range 0-4 instead of 1-5\n",
    "#         self.token2idx = lambda x: self.vocab[x]  # Converts token to index\n",
    "#         self.idx2token = lambda x: self.vocab.itos[int(x)]   # converts index to token\n",
    "#         self.encode = lambda x:[self.token2idx(token) for token in preprocessing(x)]    # encode every token with its index\n",
    "#         self.pad = lambda x: x + (max_seq_len - len(x)) * [self.token2idx(\"<pad>\")]     # add the index of \"<pad>\" as many time as needed to reach max_seq_len\n",
    "#         sequences = [self.encode(sequence)[:max_seq_len] for sequence in df.review.tolist()]    # truncate the sequence if it's longer than max_seq_len\n",
    "#         sequence, self.labels = zip(*[(sequence, label_pipeline(label)) for sequence, label in zip(sequences, df.star.tolist()) if sequence]) # map every sequence to its label\n",
    "#         self.sequences = [self.pad(sequence) for sequence in sequences]\n",
    "\n",
    "#     # mandatory methods for custom dataloader\n",
    "#     def __len__(self):\n",
    "#         return len(self.sequences)\n",
    "\n",
    "#     def __getitem__(self, i):\n",
    "#         assert len(self.sequences[i]) == self.max_seq_len\n",
    "#         return self.sequences[i], self.labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'min_freq'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\andre\\Documents\\Strive_repository\\local_exercise\\Chapter 03\\18. Semantic Analysis\\test.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/andre/Documents/Strive_repository/local_exercise/Chapter%2003/18.%20Semantic%20Analysis/test.ipynb#ch0000015?line=0'>1</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m TrainData(train_df, max_seq_len\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\andre\\Documents\\Strive_repository\\local_exercise\\Chapter 03\\18. Semantic Analysis\\test.ipynb Cell 15'\u001b[0m in \u001b[0;36mTrainData.__init__\u001b[1;34m(self, df, max_seq_len)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/Documents/Strive_repository/local_exercise/Chapter%2003/18.%20Semantic%20Analysis/test.ipynb#ch0000014?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m train_iter:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/Documents/Strive_repository/local_exercise/Chapter%2003/18.%20Semantic%20Analysis/test.ipynb#ch0000014?line=7'>8</a>\u001b[0m     counter\u001b[39m.\u001b[39mupdate(preprocessing(text))    \u001b[39m# update the counter object with the number of words and occurrencies\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/andre/Documents/Strive_repository/local_exercise/Chapter%2003/18.%20Semantic%20Analysis/test.ipynb#ch0000014?line=8'>9</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab \u001b[39m=\u001b[39m Vocab(counter, min_freq\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)    \u001b[39m# create pytorch Vocab from the counter with all the words (min_freq=1)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/andre/Documents/Strive_repository/local_exercise/Chapter%2003/18.%20Semantic%20Analysis/test.ipynb#ch0000014?line=9'>10</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab\u001b[39m.\u001b[39mload_vectors(\u001b[39m\"\u001b[39m\u001b[39mfasttext.simple.300d\u001b[39m\u001b[39m\"\u001b[39m)    \u001b[39m# load pretrained embeddings\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/andre/Documents/Strive_repository/local_exercise/Chapter%2003/18.%20Semantic%20Analysis/test.ipynb#ch0000014?line=10'>11</a>\u001b[0m label_pipeline \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: \u001b[39mint\u001b[39m(x) \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m     \u001b[39m# make the label range 0-4 instead of 1-5\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'min_freq'"
     ]
    }
   ],
   "source": [
    "# train_dataset = TrainData(train_df, max_seq_len=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext = FastText(\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    df = pd.read_csv(path, header=None, nrows=3000, skiprows=1, usecols=[1,2,3])\n",
    "    df.rename({1: 'star', 2: 'rating1', 3: 'rating2'}, axis=1, inplace=True)\n",
    "    df['review'] = df['rating1'] + ' ' + df['rating2']\n",
    "    df.drop(columns=['rating1', 'rating2'], inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, train_size=0.8):\n",
    "    df_idx = [i for i in range(len(df))]\n",
    "    np.random.shuffle(df_idx)\n",
    "    len_train = int(len(df) * train_size)\n",
    "    df_train = df.iloc[:len_train].reset_index(drop=True)\n",
    "    df_test = df.iloc[len_train:].reset_index(drop=True)\n",
    "    return df_train, df_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(sentence):\n",
    "    \"\"\"\n",
    "    Get rid of special symbols, lower case the words.\n",
    "    return token list\n",
    "    \"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_punct and not token.is_space and not token.is_stop]\n",
    "    return tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_encoder(token, vec):\n",
    "    if token == \"<pad>\":\n",
    "        return 1\n",
    "    else:\n",
    "        try:\n",
    "            return vec.stoi[token]\n",
    "        except:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(tokens, vec):\n",
    "    return [token_encoder(token, vec) for token in tokens]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(list_of_idx, max_seq_len, padding_index=1):\n",
    "    output = list_of_idx + (max_seq_len - len(list_of_idx))*[padding_index]\n",
    "    return output[:max_seq_len]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainData(Dataset):\n",
    "    def __init__(self, df, max_seq_len=32): # df is the input df, max_seq_len is the max lenght allowed to a sentence before cutting or padding\n",
    "        self.max_seq_len = max_seq_len\n",
    "        \n",
    "        counter = Counter()\n",
    "        train_iter = iter(df.review.values)\n",
    "        self.vec = FastText(\"simple\")\n",
    "        self.vec.vectors[1] = -torch.ones(self.vec.vectors[1].shape[0]) # replacing the vector associated with 1 (padded value) to become a vector of -1.\n",
    "        self.vec.vectors[0] = torch.zeros(self.vec.vectors[0].shape[0]) # replacing the vector associated with 0 (unknown) to become zeros\n",
    "        self.vectorizer = lambda x: self.vec.vectors[x]\n",
    "        self.labels = df.star\n",
    "        sequences = [padding(encoder(preprocessing(sequence), self.vec), max_seq_len) for sequence in df.review.tolist()]\n",
    "        self.sequences = sequences\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        assert len(self.sequences[i]) == self.max_seq_len\n",
    "        return self.sequences[i], self.labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 1, 2, 4], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "df = load_data('.data/Amazon/3000test.csv')\n",
    "df.star = df.star.apply(lambda x: int(x) -1)\n",
    "\n",
    "train_df, test_df = train_test_split(df)\n",
    "train_df, test_df = TrainData(train_df), TrainData(test_df)\n",
    "df.star.unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_train(batch, vectorizer=train_df.vectorizer):\n",
    "    inputs = torch.stack([torch.stack([vectorizer(token) for token in sentence[0]]) for sentence in batch])\n",
    "    target = torch.LongTensor([item[1] for item in batch])\n",
    "    return inputs, target\n",
    "\n",
    "def collate_test(batch, vectorizer=test_df.vectorizer):\n",
    "    inputs = torch.stack([torch.stack([vectorizer(token) for token in sentence[0]]) for sentence in batch])\n",
    "    target = torch.LongTensor([item[1] for item in batch])\n",
    "    return inputs, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_df, batch_size=BATCH_SIZE, collate_fn=collate_train, shuffle=True)\n",
    "test_loader = DataLoader(test_df, batch_size=BATCH_SIZE, collate_fn=collate_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "emb_dim = 300\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, max_seq_len, emb_dim, hidden1=16, hidden2=16):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(max_seq_len*emb_dim, hidden1)\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.fc3 = nn.Linear(hidden2, 5)\n",
    "        self.out = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = F.relu(self.fc1(inputs.squeeze(1).float()))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (fc1): Linear(in_features=9600, out_features=16, bias=True)\n",
       "  (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (fc3): Linear(in_features=16, out_features=5, bias=True)\n",
       "  (out): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQ_LEN = 32\n",
    "model = Classifier(MAX_SEQ_LEN, 300, 16, 16)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Only train the classifier parameters, feature parameters are frozen\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Train loss: 1.6479, Test loss: 1.6320, Accuracy: 0.1552\n",
      "Epoch: 2/100, Train loss: 1.5731, Test loss: 1.6052, Accuracy: 0.2122\n",
      "Epoch: 3/100, Train loss: 1.4257, Test loss: 1.6084, Accuracy: 0.2599\n",
      "Epoch: 4/100, Train loss: 1.1419, Test loss: 1.8773, Accuracy: 0.2719\n",
      "Epoch: 5/100, Train loss: 0.9189, Test loss: 2.2688, Accuracy: 0.2610\n",
      "Epoch: 6/100, Train loss: 0.8283, Test loss: 2.5315, Accuracy: 0.2237\n",
      "Epoch: 7/100, Train loss: 0.7864, Test loss: 2.7323, Accuracy: 0.2484\n",
      "Epoch: 8/100, Train loss: 0.7664, Test loss: 2.8125, Accuracy: 0.2654\n",
      "Epoch: 9/100, Train loss: 0.7615, Test loss: 2.9639, Accuracy: 0.2489\n",
      "Epoch: 10/100, Train loss: 0.7504, Test loss: 3.0427, Accuracy: 0.2133\n",
      "Epoch: 11/100, Train loss: 0.7463, Test loss: 3.0845, Accuracy: 0.2319\n",
      "Epoch: 12/100, Train loss: 0.7418, Test loss: 3.2442, Accuracy: 0.2122\n",
      "Epoch: 13/100, Train loss: 0.7411, Test loss: 3.3576, Accuracy: 0.2012\n",
      "Epoch: 14/100, Train loss: 0.7376, Test loss: 3.4967, Accuracy: 0.2177\n",
      "Epoch: 15/100, Train loss: 0.7436, Test loss: 3.4828, Accuracy: 0.2522\n",
      "Epoch: 16/100, Train loss: 0.7267, Test loss: 3.6061, Accuracy: 0.2489\n",
      "Epoch: 17/100, Train loss: 0.7528, Test loss: 3.7283, Accuracy: 0.2368\n",
      "Epoch: 18/100, Train loss: 0.7405, Test loss: 3.6604, Accuracy: 0.2588\n",
      "Epoch: 19/100, Train loss: 0.7139, Test loss: 4.0821, Accuracy: 0.2566\n",
      "Epoch: 20/100, Train loss: 0.7038, Test loss: 3.9980, Accuracy: 0.2719\n",
      "Epoch: 21/100, Train loss: 0.7356, Test loss: 3.6860, Accuracy: 0.2034\n",
      "Epoch: 22/100, Train loss: 0.8535, Test loss: 3.6866, Accuracy: 0.1793\n",
      "Epoch: 23/100, Train loss: 0.7898, Test loss: 3.3329, Accuracy: 0.2319\n",
      "Epoch: 24/100, Train loss: 0.7023, Test loss: 4.2546, Accuracy: 0.2385\n",
      "Epoch: 25/100, Train loss: 0.6812, Test loss: 3.8420, Accuracy: 0.2116\n",
      "Epoch: 26/100, Train loss: 0.7111, Test loss: 4.1200, Accuracy: 0.2155\n",
      "Epoch: 27/100, Train loss: 0.6968, Test loss: 4.0717, Accuracy: 0.2270\n",
      "Epoch: 28/100, Train loss: 0.6934, Test loss: 4.1232, Accuracy: 0.2188\n",
      "Epoch: 29/100, Train loss: 0.6563, Test loss: 4.2584, Accuracy: 0.2780\n",
      "Epoch: 30/100, Train loss: 0.6755, Test loss: 4.3288, Accuracy: 0.2193\n",
      "Epoch: 31/100, Train loss: 0.6633, Test loss: 4.3786, Accuracy: 0.1968\n",
      "Epoch: 32/100, Train loss: 0.6631, Test loss: 4.2021, Accuracy: 0.2462\n",
      "Epoch: 33/100, Train loss: 0.6184, Test loss: 4.6013, Accuracy: 0.2456\n",
      "Epoch: 34/100, Train loss: 0.6385, Test loss: 4.7612, Accuracy: 0.2456\n",
      "Epoch: 35/100, Train loss: 0.6378, Test loss: 4.3613, Accuracy: 0.2484\n",
      "Epoch: 36/100, Train loss: 0.5941, Test loss: 4.4556, Accuracy: 0.2473\n",
      "Epoch: 37/100, Train loss: 0.6195, Test loss: 4.4813, Accuracy: 0.2105\n",
      "Epoch: 38/100, Train loss: 0.5707, Test loss: 4.6572, Accuracy: 0.2648\n",
      "Epoch: 39/100, Train loss: 0.5809, Test loss: 4.6460, Accuracy: 0.2248\n",
      "Epoch: 40/100, Train loss: 0.5512, Test loss: 4.6523, Accuracy: 0.2462\n",
      "Epoch: 41/100, Train loss: 0.5441, Test loss: 4.7184, Accuracy: 0.2533\n",
      "Epoch: 42/100, Train loss: 0.5340, Test loss: 4.9832, Accuracy: 0.2648\n",
      "Epoch: 43/100, Train loss: 0.5321, Test loss: 4.8217, Accuracy: 0.2248\n",
      "Epoch: 44/100, Train loss: 0.5358, Test loss: 5.1734, Accuracy: 0.2566\n",
      "Epoch: 45/100, Train loss: 0.4718, Test loss: 5.3109, Accuracy: 0.2593\n",
      "Epoch: 46/100, Train loss: 0.4551, Test loss: 5.7570, Accuracy: 0.2352\n",
      "Epoch: 47/100, Train loss: 0.5406, Test loss: 5.3020, Accuracy: 0.2977\n",
      "Epoch: 48/100, Train loss: 0.4428, Test loss: 5.4748, Accuracy: 0.2621\n",
      "Epoch: 49/100, Train loss: 0.4007, Test loss: 5.5421, Accuracy: 0.2763\n",
      "Epoch: 50/100, Train loss: 0.4283, Test loss: 5.6811, Accuracy: 0.2588\n",
      "Epoch: 51/100, Train loss: 0.3885, Test loss: 5.4948, Accuracy: 0.2489\n",
      "Epoch: 52/100, Train loss: 0.3685, Test loss: 6.0963, Accuracy: 0.2527\n",
      "Epoch: 53/100, Train loss: 0.3402, Test loss: 6.1771, Accuracy: 0.2708\n",
      "Epoch: 54/100, Train loss: 0.3547, Test loss: 6.3517, Accuracy: 0.2758\n",
      "Epoch: 55/100, Train loss: 0.3695, Test loss: 6.3482, Accuracy: 0.2522\n",
      "Epoch: 56/100, Train loss: 0.3666, Test loss: 5.5024, Accuracy: 0.2533\n",
      "Epoch: 57/100, Train loss: 0.4897, Test loss: 5.6950, Accuracy: 0.2308\n",
      "Epoch: 58/100, Train loss: 0.3156, Test loss: 6.3457, Accuracy: 0.2664\n",
      "Epoch: 59/100, Train loss: 0.2762, Test loss: 6.2451, Accuracy: 0.2621\n",
      "Epoch: 60/100, Train loss: 0.2877, Test loss: 6.3551, Accuracy: 0.2769\n",
      "Epoch: 61/100, Train loss: 0.2470, Test loss: 7.0867, Accuracy: 0.2495\n",
      "Epoch: 62/100, Train loss: 0.3228, Test loss: 6.1178, Accuracy: 0.2703\n",
      "Epoch: 63/100, Train loss: 0.2599, Test loss: 6.6919, Accuracy: 0.2703\n",
      "Epoch: 64/100, Train loss: 0.2573, Test loss: 6.6549, Accuracy: 0.2478\n",
      "Epoch: 65/100, Train loss: 0.2238, Test loss: 6.9570, Accuracy: 0.2560\n",
      "Epoch: 66/100, Train loss: 0.1878, Test loss: 7.1159, Accuracy: 0.2473\n",
      "Epoch: 67/100, Train loss: 0.2206, Test loss: 7.2435, Accuracy: 0.2582\n",
      "Epoch: 68/100, Train loss: 0.2977, Test loss: 7.7498, Accuracy: 0.2451\n",
      "Epoch: 69/100, Train loss: 0.2804, Test loss: 6.9044, Accuracy: 0.2610\n",
      "Epoch: 70/100, Train loss: 0.2029, Test loss: 7.2550, Accuracy: 0.2637\n",
      "Epoch: 71/100, Train loss: 0.1403, Test loss: 7.5131, Accuracy: 0.2495\n",
      "Epoch: 72/100, Train loss: 0.1979, Test loss: 7.5702, Accuracy: 0.2555\n",
      "Epoch: 73/100, Train loss: 0.1596, Test loss: 7.7118, Accuracy: 0.2533\n",
      "Epoch: 74/100, Train loss: 0.2057, Test loss: 7.7694, Accuracy: 0.2505\n",
      "Epoch: 75/100, Train loss: 0.1875, Test loss: 7.4609, Accuracy: 0.2708\n",
      "Epoch: 76/100, Train loss: 0.1731, Test loss: 7.8717, Accuracy: 0.2582\n",
      "Epoch: 77/100, Train loss: 0.1047, Test loss: 8.1049, Accuracy: 0.2484\n",
      "Epoch: 78/100, Train loss: 0.1606, Test loss: 8.1303, Accuracy: 0.2610\n",
      "Epoch: 79/100, Train loss: 0.0819, Test loss: 8.2455, Accuracy: 0.2599\n",
      "Epoch: 80/100, Train loss: 0.0809, Test loss: 8.6294, Accuracy: 0.2516\n",
      "Epoch: 81/100, Train loss: 0.1738, Test loss: 9.4369, Accuracy: 0.2626\n",
      "Epoch: 82/100, Train loss: 0.3388, Test loss: 8.2241, Accuracy: 0.2632\n",
      "Epoch: 83/100, Train loss: 0.0903, Test loss: 8.5120, Accuracy: 0.2549\n",
      "Epoch: 84/100, Train loss: 0.1043, Test loss: 8.8895, Accuracy: 0.2615\n",
      "Epoch: 85/100, Train loss: 0.1107, Test loss: 8.4357, Accuracy: 0.2648\n",
      "Epoch: 86/100, Train loss: 0.1980, Test loss: 8.0936, Accuracy: 0.2686\n",
      "Epoch: 87/100, Train loss: 0.1048, Test loss: 8.4494, Accuracy: 0.2703\n",
      "Epoch: 88/100, Train loss: 0.0818, Test loss: 8.6239, Accuracy: 0.2785\n",
      "Epoch: 89/100, Train loss: 0.0689, Test loss: 8.7384, Accuracy: 0.2708\n",
      "Epoch: 90/100, Train loss: 0.0576, Test loss: 8.9362, Accuracy: 0.2736\n",
      "Epoch: 91/100, Train loss: 0.0527, Test loss: 9.2273, Accuracy: 0.2670\n",
      "Epoch: 92/100, Train loss: 0.0634, Test loss: 9.2084, Accuracy: 0.2758\n",
      "Epoch: 93/100, Train loss: 0.0672, Test loss: 9.4468, Accuracy: 0.2654\n",
      "Epoch: 94/100, Train loss: 0.0845, Test loss: 9.7449, Accuracy: 0.2654\n",
      "Epoch: 95/100, Train loss: 0.0468, Test loss: 9.9840, Accuracy: 0.2664\n",
      "Epoch: 96/100, Train loss: 0.1306, Test loss: 9.7299, Accuracy: 0.2769\n",
      "Epoch: 97/100, Train loss: 0.0875, Test loss: 9.7462, Accuracy: 0.2719\n",
      "Epoch: 98/100, Train loss: 0.0570, Test loss: 9.5461, Accuracy: 0.2648\n",
      "Epoch: 99/100, Train loss: 0.0396, Test loss: 9.7281, Accuracy: 0.2621\n",
      "Epoch: 100/100, Train loss: 0.0435, Test loss: 9.8037, Accuracy: 0.2544\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 100\n",
    "print_every = 40\n",
    "train_losses, test_losses, accuracies = [], [], []\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss, running_test_losses, running_test_accuracy = 0, 0, 0\n",
    "    # print(f\"Epoch: {e+1}/{epochs}\")\n",
    "\n",
    "    for i, (sentences, labels) in enumerate(iter(train_loader)):\n",
    "\n",
    "        sentences.resize_(sentences.size()[0], 32* emb_dim)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(sentences)   # 1) Forward pass\n",
    "        train_loss = criterion(output, labels) # 2) Compute loss\n",
    "        train_loss.backward()                  # 3) Backward pass\n",
    "        optimizer.step()                 # 4) Update model\n",
    "        \n",
    "        running_loss += train_loss.item()\n",
    "        \n",
    "        # if i % print_every == 0:\n",
    "        #     print(f\"\\tIteration: {i}\\t Loss: {running_loss/print_every:.4f}\")\n",
    "        #     running_loss = 0\n",
    "    avg_running_loss = running_loss/len(train_loader)\n",
    "    train_losses.append(avg_running_loss)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (sentences_test, labels_test) in enumerate(iter(test_loader)):\n",
    "            sentences_test.resize_(sentences_test.size()[0], 32* emb_dim)\n",
    "\n",
    "            output_test = model.forward(sentences_test)\n",
    "            test_loss = criterion(output_test, labels_test)\n",
    "\n",
    "            running_test_losses += test_loss.item()\n",
    "\n",
    "            prediction_label = torch.argmax(output_test, dim=1)\n",
    "            running_test_accuracy += (prediction_label == labels_test).sum() / len(labels_test)\n",
    "        avg_test_loss = running_test_losses/len(test_loader)\n",
    "        test_losses.append(avg_test_loss)\n",
    "        avg_running_accuracy = running_test_accuracy/len(test_loader)\n",
    "        accuracies.append(avg_running_accuracy)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    print(f\"Epoch: {e+1}/{epochs}, Train loss: {avg_running_loss:.4f}, Test loss: {avg_test_loss:.4f}, Accuracy: {avg_running_accuracy:.4f}\" )\n",
    "\n",
    "torch.save({'model_state': model.state_dict()}, 'final_model')\n",
    "plt.plot(train_losses, label='Train loss')\n",
    "plt.plot(test_losses, label='Test losses')\n",
    "plt.plot(accuracies, label='Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca6d8dca7ea44f50a219602c5adcd3e65ceab2675748fe45a38b1f25aedd036e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
